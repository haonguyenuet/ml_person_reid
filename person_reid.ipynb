{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "person_reid.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cvC-yUPIVrzl",
        "Cgx9IhNbVY4f",
        "MnfB5FeIV7H0",
        "217qDx8QWbDX",
        "cA3-twA9dZKb",
        "wcbDx2_-VwHQ",
        "pkyDoVXrsUF0",
        "L7K_dd6PUvqy",
        "ndMdX8bBVhmp",
        "q9QGv9w4V5kY",
        "yzEoO85MWexR",
        "4gIwqpLAXQ_p",
        "6sKzI1Sctg6-",
        "kNXaeM5kLvtr",
        "5VrITMEkkdAw",
        "SnamFFg12SeI",
        "CR1fzqbNsAb4",
        "W05gC2xhtAFH",
        "mNjqYgJXtM_A",
        "OjLFxBeitS-I",
        "z8qTSnRytXg3",
        "VCQtsPSjtdvl",
        "8-CLi5Mk567l",
        "xq12FDTLgNoD"
      ],
      "authorship_tag": "ABX9TyN3jFLuBR6idIysuzAcoo8o",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haonguyenuet/person_reid/blob/master/person_reid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXTn5U-mULeR"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import functional as F\n",
        "from torch import nn\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from collections import namedtuple\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "import tarfile\n",
        "import zipfile\n",
        "import re\n",
        "import glob\n",
        "import urllib\n",
        "import sys\n",
        "import warnings\n",
        "import errno\n",
        "import unittest"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvC-yUPIVrzl"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "461YxxkXVwe_"
      },
      "source": [
        "def mkdir_if_missing(dirname):\n",
        "    \"\"\"Creates dirname if it is missing.\"\"\"\n",
        "    if not osp.exists(dirname):\n",
        "        try:\n",
        "            os.makedirs(dirname)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise\n",
        "\n",
        "\n",
        "def isfile(fpath):\n",
        "    isfile = osp.isfile(fpath)\n",
        "    if not isfile:\n",
        "        warnings.warn('No file found at \"{}\"'.format(fpath))\n",
        "    return isfile\n",
        "\n",
        "def read_image(path):\n",
        "    got_img = False\n",
        "    if not osp.exists(path):\n",
        "        raise IOError('\"{}\" does not exist'.format(path))\n",
        "    while not got_img:\n",
        "        try:\n",
        "            img = Image.open(path).convert('RGB')\n",
        "            got_img = True\n",
        "        except IOError:\n",
        "            print(\n",
        "                'IOError incurred when reading \"{}\". Will redo. Don\\'t worry. Just chill.'\n",
        "                .format(path)\n",
        "            )\n",
        "    return img\n",
        "\n",
        "def download_url(url, dst):\n",
        "    \"\"\"Downloads file from a url to a destination.\n",
        "    Args:\n",
        "        url (str): url to download file.\n",
        "        dst (str): destination path.\n",
        "    \"\"\"\n",
        "    print('* url=\"{}\"'.format(url))\n",
        "    print('* destination=\"{}\"'.format(dst))\n",
        "\n",
        "    def _reporthook(count, block_size, total_size):\n",
        "        progress_size = int(count * block_size)\n",
        "        percent = int(progress_size * 100 / total_size)\n",
        "        sys.stdout.write(\n",
        "            '\\r...%d%%, %d MB' %\n",
        "            (percent, progress_size / (1024*1024))\n",
        "        )\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    urllib.request.urlretrieve(url, dst, _reporthook)\n",
        "    sys.stdout.write('\\n')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oecIPOoBfUJY"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgx9IhNbVY4f"
      },
      "source": [
        "#Prepare Data âœ”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnfB5FeIV7H0"
      },
      "source": [
        "### ImageDataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ETLrGNcV-09"
      },
      "source": [
        "class ImageDataset(object):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        train (list): contains tuples of (img_path(s), pid, camid).\n",
        "        query (list): contains tuples of (img_path(s), pid, camid).\n",
        "        gallery (list): contains tuples of (img_path(s), pid, camid).\n",
        "        transform: transform function.\n",
        "        mode (str): 'train', 'query' or 'gallery'.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        train,\n",
        "        query,\n",
        "        gallery,\n",
        "        mode='train',\n",
        "        transform=None,\n",
        "    ):\n",
        "        # adding a dataset indicator \"dsetid\"\n",
        "        # (img_path(s), pid, camid) ==> (img_path(s), pid, camid, dsetid)\n",
        "\n",
        "        if len(train[0]) == 3:\n",
        "            train = [(*items, 0) for items in train]\n",
        "        if len(query[0]) == 3:\n",
        "            query = [(*items, 0) for items in query]\n",
        "        if len(gallery[0]) == 3:\n",
        "            gallery = [(*items, 0) for items in gallery]\n",
        "\n",
        "        self.train = train\n",
        "        self.query = query\n",
        "        self.gallery = gallery\n",
        "        self.transform = transform\n",
        "        self.mode = mode\n",
        "\n",
        "        self.num_train_pids = self.get_num_pids(self.train)\n",
        "        self.num_train_cams = self.get_num_cams(self.train)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self.data = self.train\n",
        "        elif self.mode == 'query':\n",
        "            self.data = self.query\n",
        "        elif self.mode == 'gallery':\n",
        "            self.data = self.gallery\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                'Invalid mode. Got {}, but expected to be '\n",
        "                'one of [train | query | gallery]'.format(self.mode)\n",
        "            )\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img_path, pid, camid, dsetid = self.data[index]\n",
        "        img = read_image(img_path)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        item = {\n",
        "            'img': img,\n",
        "            'pid': pid,\n",
        "            'camid': camid,\n",
        "            'impath': img_path,\n",
        "            'dsetid': dsetid\n",
        "        }\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def get_num_pids(self, data):\n",
        "        pids = set()\n",
        "        for items in data:\n",
        "            pid = items[1]\n",
        "            pids.add(pid)\n",
        "        return len(pids)\n",
        "\n",
        "    def get_num_cams(self, data):\n",
        "        cams = set()\n",
        "        for items in data:\n",
        "            camid = items[2]\n",
        "            cams.add(camid)\n",
        "        return len(cams)\n",
        "\n",
        "    def download_dataset(self, dataset_dir, dataset_url):\n",
        "        if osp.exists(dataset_dir):\n",
        "            return\n",
        "\n",
        "        print('Creating directory \"{}\"'.format(dataset_dir))\n",
        "        mkdir_if_missing(dataset_dir)\n",
        "        fpath = osp.join(dataset_dir, osp.basename(dataset_url))\n",
        "\n",
        "        download_url(dataset_url, fpath)\n",
        "        print('Extracting \"{}\"'.format(fpath))\n",
        "        try:\n",
        "            tar = tarfile.open(fpath)\n",
        "            tar.extractall(path=dataset_dir)\n",
        "            tar.close()\n",
        "        except:\n",
        "            zip_ref = zipfile.ZipFile(fpath, 'r')\n",
        "            zip_ref.extractall(dataset_dir)\n",
        "            zip_ref.close()\n",
        "\n",
        "        print('{} dataset is ready'.format(self.__class__.__name__))\n",
        "\n",
        "    def check_required_files(self, required_files):\n",
        "        for fpath in required_files:\n",
        "            if not osp.exists(fpath):\n",
        "                raise RuntimeError('\"{}\" is not found'.format(fpath))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "217qDx8QWbDX"
      },
      "source": [
        "### Market1501\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfdQVF9WWhlv"
      },
      "source": [
        "class Market1501(ImageDataset):\n",
        "    dataset_dir = 'market1501'\n",
        "    dataset_url = 'http://188.138.127.15:81/Datasets/Market-1501-v15.09.15.zip'\n",
        "\n",
        "    def __init__(self, root='', **kwargs):\n",
        "        self.root = osp.abspath(osp.expanduser(root))\n",
        "        self.dataset_dir = osp.join(self.root, self.dataset_dir)\n",
        "        self.download_dataset(self.dataset_dir, self.dataset_url)\n",
        "\n",
        "        data_dir = osp.join(self.dataset_dir, 'Market-1501-v15.09.15')\n",
        "        if osp.isdir(data_dir):\n",
        "            self.data_dir = data_dir\n",
        "\n",
        "        self.train_dir = osp.join(self.data_dir, 'bounding_box_train')\n",
        "        self.query_dir = osp.join(self.data_dir, 'query')\n",
        "        self.gallery_dir = osp.join(self.data_dir, 'bounding_box_test')\n",
        "\n",
        "        required_files = [\n",
        "            self.data_dir, self.train_dir, self.query_dir, self.gallery_dir\n",
        "        ]\n",
        "        self.check_required_files(required_files)\n",
        "\n",
        "        train = self.process_dir(self.train_dir, relabel=True)\n",
        "        query = self.process_dir(self.query_dir, relabel=False)\n",
        "        gallery = self.process_dir(self.gallery_dir, relabel=False)\n",
        "      \n",
        "        super().__init__(train, query, gallery, **kwargs)\n",
        "\n",
        "    def process_dir(self, dir_path, relabel=False):\n",
        "        img_paths = glob.glob(osp.join(dir_path, '*.jpg'))\n",
        "        pattern = re.compile(r'([-\\d]+)_c(\\d)')\n",
        "\n",
        "        pid_container = set()\n",
        "        for img_path in img_paths:\n",
        "            pid, _ = map(int, pattern.search(img_path).groups())\n",
        "            if pid == -1:\n",
        "                continue # junk images are just ignored\n",
        "            pid_container.add(pid)\n",
        "        pid2label = {pid: label for label, pid in enumerate(pid_container)}\n",
        "\n",
        "        data = []\n",
        "        for img_path in img_paths:\n",
        "            pid, camid = map(int, pattern.search(img_path).groups())\n",
        "            if pid == -1:\n",
        "                continue # junk images are just ignored\n",
        "            assert 0 <= pid <= 1501 # pid == 0 means background\n",
        "            assert 1 <= camid <= 6\n",
        "            camid -= 1 # index starts from 0\n",
        "            if relabel:\n",
        "                pid = pid2label[pid]\n",
        "            data.append((img_path, pid, camid))\n",
        "\n",
        "        return data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA3-twA9dZKb"
      },
      "source": [
        "### DataPreparer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyzyejmSdy1i"
      },
      "source": [
        "QueryGallery = namedtuple('QueryGallery', ['query', 'gallery'])\n",
        "TrainTest = namedtuple('TrainTest', ['train', 'test'])\n",
        "\n",
        "class DataPreparer(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        root=\"\",\n",
        "        batch_size_train=32,\n",
        "        batch_size_test=32,\n",
        "        workers=4,\n",
        "    ):\n",
        "        self.root = root\n",
        "        self._build_transforms()\n",
        "        self._prepare_data()\n",
        "        self._prepare_loader(batch_size_train, batch_size_test, workers)\n",
        "\n",
        "        self._num_train_pids = self.trainset.num_train_pids\n",
        "        self._num_train_cams = self.trainset.num_train_cams\n",
        "\n",
        "    @property\n",
        "    def num_train_pids(self):\n",
        "        return self._num_train_pids\n",
        "\n",
        "    @property\n",
        "    def num_train_cams(self):\n",
        "        return self._num_train_cams\n",
        "        \n",
        "    def _build_transforms(self):\n",
        "        norm_mean = [0.485, 0.456, 0.406]\n",
        "        norm_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "        self.transform_train = T.Compose([\n",
        "            T.Resize((256, 128)),\n",
        "            T.Pad(10),\n",
        "            T.RandomCrop((256,128)),\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=norm_mean, std=norm_std),\n",
        "        ])\n",
        "\n",
        "        self.transform_test = T.Compose([\n",
        "            T.Resize((256, 128)),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=norm_mean, std=norm_std),\n",
        "        ])\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        print('=> Loading train (source) dataset')\n",
        "        self.trainset = Market1501(\n",
        "            root=self.root,\n",
        "            mode='train',\n",
        "            transform=self.transform_train\n",
        "        )\n",
        "\n",
        "        self.queryset = Market1501(\n",
        "            root=self.root,\n",
        "            mode='query',\n",
        "            transform=self.transform_test\n",
        "        )\n",
        "\n",
        "        self.galleryset = Market1501(\n",
        "            root=self.root,\n",
        "            mode='gallery',\n",
        "            transform=self.transform_test\n",
        "        )\n",
        "\n",
        "    def _prepare_loader(self, batch_size_train, batch_size_test, workers):\n",
        "        self.trainloader = DataLoader(\n",
        "            dataset=self.trainset,\n",
        "            batch_size=batch_size_train,\n",
        "            shuffle=True,\n",
        "            num_workers=workers,\n",
        "            drop_last=True\n",
        "        )\n",
        "\n",
        "        self.testloader = QueryGallery(\n",
        "            query=DataLoader(\n",
        "                dataset=self.queryset,\n",
        "                batch_size=batch_size_test,\n",
        "                shuffle=True,\n",
        "                num_workers=workers\n",
        "            ),\n",
        "            gallery=DataLoader(\n",
        "                dataset=self.galleryset,\n",
        "                batch_size=batch_size_test,\n",
        "                shuffle=True,\n",
        "                num_workers=workers\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def fetch_loader(self):\n",
        "        return TrainTest(train=self.trainloader, test=self.testloader)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2Eme0YV46e6E",
        "outputId": "6e615e21-e1c3-468f-fe24-ce106a5b4921"
      },
      "source": [
        "preparer = DataPreparer(root = \"./data\")\n",
        "print(\"number of train pids:\", preparer.num_train_pids)\n",
        "print(\"number of train cids:\", preparer.num_train_cams)\n",
        "\n",
        "data = iter(preparer.trainloader).next()\n",
        "imgs, pids = data['img'], data['pid']\n",
        "print(pids[31])\n",
        "print(imgs[31].shape)\n",
        "plt.imshow(imgs[31].permute(1, 2, 0))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Loading train (source) dataset\n",
            "Creating directory \"/content/data/market1501\"\n",
            "* url=\"http://188.138.127.15:81/Datasets/Market-1501-v15.09.15.zip\"\n",
            "* destination=\"/content/data/market1501/Market-1501-v15.09.15.zip\"\n",
            "...100%, 145 MB\n",
            "Extracting \"/content/data/market1501/Market-1501-v15.09.15.zip\"\n",
            "Market1501 dataset is ready\n",
            "number of train pids: 751\n",
            "number of train cids: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(211)\n",
            "torch.Size([3, 256, 128])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe35739a910>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcbDx2_-VwHQ"
      },
      "source": [
        "# OSNet âœ”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkyDoVXrsUF0"
      },
      "source": [
        "### Conv1x1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVryN7L9sUF1"
      },
      "source": [
        "class Conv1x1(nn.Module):\n",
        "    \"\"\" 1x1 Conv -> Batch norm -> ReLU \"\"\"\n",
        "\n",
        "    def __init__(self, c_in, c_out, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(c_in, c_out, 1, stride=stride, padding=0, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(c_out)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Conv1x1Linear(nn.Module):\n",
        "    \"\"\" 1x1 Conv -> Batch norm \"\"\"\n",
        " \n",
        "    def __init__(self, c_in, c_out, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(c_in, c_out, 1, stride=stride, padding=0, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(c_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7K_dd6PUvqy"
      },
      "source": [
        "### LightConv3x3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgpRQDJGU_Bk"
      },
      "source": [
        "class LightConv3x3(nn.Module):\n",
        "    \"\"\" 1x1 Conv -> DW 3x3 Conv -> Batch norm -> ReLU \"\"\"\n",
        "\n",
        "    def __init__(self, c_in, c_out):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(c_in, c_out, 1, stride=1, padding=0, bias=False)\n",
        "        self.depthwise = nn.Conv2d(\n",
        "            c_out, c_out, 3, stride=1, padding=1, bias=False, groups=c_out\n",
        "\t\t\t\t)\n",
        "        self.bn = nn.BatchNorm2d(c_out)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.depthwise(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndMdX8bBVhmp"
      },
      "source": [
        "### ConvLayer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hROJTzImVlkI"
      },
      "source": [
        "class ConvLayer(nn.Module):\n",
        "    \"\"\"Conv -> Batch norm -> ReLU\"\"\"\n",
        "\n",
        "    def __init__(self, c_in, c_out, kernel_size, stride=1, padding=0, groups=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(c_in, c_out, kernel_size, stride=stride,\n",
        "                              padding=padding, bias=False, groups=groups)\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(c_out)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9QGv9w4V5kY"
      },
      "source": [
        "### AggregationGate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l06qVNmoWAI_"
      },
      "source": [
        "class AggregationGate(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in):\n",
        "        super().__init__()\n",
        "        reduction = 16\n",
        "        self.global_avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Conv2d(c_in, c_in//reduction, kernel_size=1, bias=True, padding=0)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc2 = nn.Conv2d(c_in//reduction, c_in, kernel_size=1, bias=True, padding=0)\n",
        "        self.activation = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        output = self.global_avgpool(x)\n",
        "        output = self.fc1(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.fc2(output)\n",
        "        output = self.activation(output)\n",
        "        return output * x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzEoO85MWexR"
      },
      "source": [
        "### OSResBlock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptCkYgxVWigS"
      },
      "source": [
        "class OSResBlock(nn.Module):\n",
        "    def __init__(self, c_in, c_out, bottleneck_reduction=4, **kwargs):\n",
        "        super().__init__()\n",
        "        c_mid = c_out // bottleneck_reduction\n",
        "        self.conv1 = Conv1x1(c_in, c_mid)\n",
        "        self.conv2a = LightConv3x3(c_mid, c_mid)\n",
        "        self.conv2b = nn.Sequential(\n",
        "            LightConv3x3(c_mid, c_mid),\n",
        "            LightConv3x3(c_mid, c_mid),\n",
        "        )\n",
        "        self.conv2c = nn.Sequential(\n",
        "            LightConv3x3(c_mid, c_mid),\n",
        "            LightConv3x3(c_mid, c_mid),\n",
        "            LightConv3x3(c_mid, c_mid),\n",
        "        )\n",
        "        self.conv2d = nn.Sequential(\n",
        "            LightConv3x3(c_mid, c_mid),\n",
        "            LightConv3x3(c_mid, c_mid),\n",
        "            LightConv3x3(c_mid, c_mid),\n",
        "            LightConv3x3(c_mid, c_mid),\n",
        "        )\n",
        "        self.gate = AggregationGate(c_mid)\n",
        "        self.conv3 = Conv1x1Linear(c_mid, c_out)\n",
        "        self.downsample = None\n",
        "        if c_in != c_out:\n",
        "            self.downsample = Conv1x1Linear(c_in, c_out)\n",
        "\t\t\t\n",
        "    def forward(self, x):\n",
        "        residual = self.conv1(x)\n",
        "        x_a = self.conv2a(residual)\n",
        "        x_b = self.conv2b(residual)\n",
        "        x_c = self.conv2c(residual)\n",
        "        x_d = self.conv2d(residual)\n",
        "        residual = self.gate(x_a) + self.gate(x_b) + self.gate(x_c) + self.gate(x_d)\n",
        "        residual = self.conv3(residual)\n",
        "        if self.downsample is not None:\n",
        "            x = self.downsample(x)\n",
        "        out = x + residual\n",
        "        return F.relu(out)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gIwqpLAXQ_p"
      },
      "source": [
        "### OSNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "046ZECf2XYrQ"
      },
      "source": [
        "class OSNet(nn.Module):\n",
        "    def __init__(self,\n",
        "\t\t\t\t\t\t\t\tnum_classes = 751, \n",
        "\t\t\t\t\t\t\t\tblocks=[OSResBlock, OSResBlock, OSResBlock], \n",
        "\t\t\t\t\t\t\t\tlayers=[2, 2, 2],\n",
        "                channels=[64, 256, 384, 512],\n",
        "\t\t\t\t\t\t\t\tfc_dim=512,\n",
        "\t\t\t\t\t\t\t\tloss='softmax'):\n",
        "        super().__init__()\n",
        "        self.loss = loss\n",
        "\n",
        "        # convolutional backbone\n",
        "        self.conv1 = ConvLayer(3, channels[0], 7, stride=2, padding=3)\n",
        "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "        self.conv2 = self._make_layer(blocks[0], layers[0], channels[0], channels[1])\n",
        "        self.tran1 =  nn.Sequential(\n",
        "                    Conv1x1(channels[1], channels[1]),\n",
        "                    nn.AvgPool2d(2, stride=2)\n",
        "        )\n",
        "        self.conv3 = self._make_layer(blocks[1], layers[1], channels[1], channels[2])\n",
        "        self.tran2 =  nn.Sequential(\n",
        "                    Conv1x1(channels[2], channels[2]),\n",
        "                    nn.AvgPool2d(2, stride=2)\n",
        "        )\n",
        "        self.conv4 = self._make_layer(blocks[2], layers[2], channels[2], channels[3])\n",
        "        self.conv5 = Conv1x1(channels[3], channels[3])\n",
        "        self.global_avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        # fully connected layer\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channels[3], fc_dim),\n",
        "            nn.BatchNorm1d(fc_dim),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.classifier = nn.Linear(fc_dim, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, num_layers, c_in, c_out):\n",
        "        layers = []\n",
        "\n",
        "        layers.append(block(c_in, c_out))\n",
        "        for i in range(1, num_layers):\n",
        "            layers.append(block(c_out, c_out))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def featuremaps(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.tran1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.tran2(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.featuremaps(x)\n",
        "        v = self.global_avgpool(x)\n",
        "        v = v.view(v.size(0), -1)\n",
        "        v = self.fc(v)\n",
        "        y = self.classifier(v)\n",
        "        return y"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sKzI1Sctg6-"
      },
      "source": [
        "# CrossEntropyLoss âœ”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImdpD7NDtlri"
      },
      "source": [
        "class CrossEntropyLoss(nn.Module):\n",
        "    def __init__(self, num_classes, use_gpu=True, label_smooth = True):\n",
        "        super(CrossEntropyLoss, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.eps = 0.1 if label_smooth else 0\n",
        "        self.use_gpu = use_gpu\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            logits: prediction matrix with shape (batch_size, num_classes).\n",
        "            targets: Each position contains the true label index\n",
        "\t\t\t\t\t\t\t\t\t\t with shape (batch_size).\n",
        "        \"\"\"\n",
        "        log_probs = self.logsoftmax(logits)\n",
        "        zeros = torch.zeros(log_probs.size())\n",
        "        y = zeros.scatter_(1, targets.unsqueeze(1).data.cpu(), 1)\n",
        "        if self.use_gpu:\n",
        "            y = y.cuda()\n",
        "        y = (1 - self.eps) * y + self.eps / self.num_classes\n",
        "        return (-y * log_probs).mean(0).sum()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNXaeM5kLvtr"
      },
      "source": [
        "# Metrics âœ”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VrITMEkkdAw"
      },
      "source": [
        "### Distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1M0f9Wmk3dR"
      },
      "source": [
        "def cosine_distance(input1, input2):\n",
        "    input1_normed = F.normalize(input1, p=2, dim=1)\n",
        "    input2_normed = F.normalize(input2, p=2, dim=1)\n",
        "    distmat = 1 - torch.mm(input1_normed, input2_normed.t())\n",
        "    return distmat"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnamFFg12SeI"
      },
      "source": [
        "### Rank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0AcxAUrMCu8"
      },
      "source": [
        "def eval_rank(distmat, q_pids, g_pids, q_camids, g_camids, max_rank = 10):\n",
        "    \"\"\" For each query identity, its gallery images from the same camera view are discarded \"\"\"\n",
        "    num_q, num_g = distmat.shape\n",
        "\n",
        "    if num_g < max_rank:\n",
        "        max_rank = num_g\n",
        "        print(\n",
        "            'Note: number of gallery samples is quite small, got {}'.\n",
        "            format(num_g)\n",
        "        )\n",
        "\n",
        "    indices = np.argsort(distmat, axis=1)\n",
        "    matches = (g_pids[indices] == q_pids[:, np.newaxis]).astype(np.int32)\n",
        "\n",
        "    # compute cmc curve for each query\n",
        "    all_cmc = []\n",
        "    all_AP = []\n",
        "    num_valid_q = 0. # number of valid query\n",
        "\n",
        "    for q_idx in range(num_q):\n",
        "        # get query pid and camid\n",
        "        q_pid = q_pids[q_idx]\n",
        "        q_camid = q_camids[q_idx]\n",
        "\n",
        "        # remove gallery samples that have the same pid and camid with query\n",
        "        order = indices[q_idx]\n",
        "        remove = (g_pids[order] == q_pid) & (g_camids[order] == q_camid)\n",
        "        keep = np.invert(remove)\n",
        "\n",
        "        # compute cmc curve\n",
        "        raw_cmc = matches[q_idx][\n",
        "            keep] # binary vector, positions with value 1 are correct matches\n",
        "        if not np.any(raw_cmc):\n",
        "            # this condition is true when query identity does not appear in gallery\n",
        "            continue\n",
        "\n",
        "        cmc = raw_cmc.cumsum()\n",
        "        cmc[cmc > 1] = 1\n",
        "\n",
        "        all_cmc.append(cmc[:max_rank])\n",
        "        num_valid_q += 1.\n",
        "\n",
        "        # compute average precision\n",
        "        # reference: https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Average_precision\n",
        "        num_rel = raw_cmc.sum()\n",
        "        tmp_cmc = raw_cmc.cumsum()\n",
        "        tmp_cmc = [x / (i+1.) for i, x in enumerate(tmp_cmc)]\n",
        "        tmp_cmc = np.asarray(tmp_cmc) * raw_cmc\n",
        "        AP = tmp_cmc.sum() / num_rel\n",
        "        all_AP.append(AP)\n",
        "\n",
        "    assert num_valid_q > 0, 'Error: all query identities do not appear in gallery'\n",
        "\n",
        "    all_cmc = np.asarray(all_cmc).astype(np.float32)\n",
        "    all_cmc = all_cmc.sum(0) / num_valid_q\n",
        "    mAP = np.mean(all_AP) * 100\n",
        "\n",
        "    return all_cmc, mAP\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR1fzqbNsAb4"
      },
      "source": [
        "# Unit Tests âœ”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W05gC2xhtAFH"
      },
      "source": [
        "### TestConv1x1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIZeZHVBuBc_"
      },
      "source": [
        "class TestConv1x1(unittest.TestCase):\n",
        "  def test_ouput(self):\n",
        "    layer1 = Conv1x1(c_in=3, c_out = 1)\n",
        "    layer2 = Conv1x1Linear(c_in=3, c_out = 1)\n",
        "    input = torch.randn(1, 3, 256, 128)\n",
        "    output1 = layer1(input)\n",
        "    output2 = layer2(input)\n",
        "\n",
        "    self.assertEqual(output1.shape, (1, 1, 256, 128))\n",
        "    self.assertEqual(output2.shape, (1, 1, 256, 128))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNjqYgJXtM_A"
      },
      "source": [
        "### TestLightConv3x3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjFPaEi85KvV"
      },
      "source": [
        "class TestLightConv3x3(unittest.TestCase):\n",
        "  def test_ouput(self):\n",
        "    layer = LightConv3x3(c_in=10, c_out = 5)\n",
        "    input = torch.randn(1, 10, 256, 128)\n",
        "    output = layer(input)\n",
        "\n",
        "    self.assertEqual(output.shape, (1, 5, 256, 128))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjLFxBeitS-I"
      },
      "source": [
        "### TestConvLayer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1bECocs6D0M"
      },
      "source": [
        "class TestConvLayer(unittest.TestCase):\n",
        "  def test_ouput(self):\n",
        "    layer1 = ConvLayer(c_in=10, c_out = 5, kernel_size=5, padding = 0)\n",
        "    layer2 = ConvLayer(c_in=10, c_out = 8, kernel_size=5, padding = 1)\n",
        "    layer3 = ConvLayer(c_in=10, c_out = 10, kernel_size=5, padding = 2)\n",
        "\n",
        "    input = torch.randn(1, 10, 256, 128)\n",
        "    output1 = layer1(input)\n",
        "    output2 = layer2(input)\n",
        "    output3 = layer3(input)\n",
        "\n",
        "    self.assertEqual(output1.shape, (1, 5, 252, 124))\n",
        "    self.assertEqual(output2.shape, (1, 8, 254, 126))\n",
        "    self.assertEqual(output3.shape, (1, 10, 256, 128))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8qTSnRytXg3"
      },
      "source": [
        "### TestOSResBlock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANOeOK_cDP3-"
      },
      "source": [
        "class TestOSResBlock(unittest.TestCase):\n",
        "  def test_ouput(self):\n",
        "    layer1 = OSResBlock(c_in=64, c_out = 128, bottleneck_reduction = 4)\n",
        "    layer2 = OSResBlock(c_in=128, c_out = 256, bottleneck_reduction = 2)\n",
        "\n",
        "    input = torch.randn(1, 64, 64, 32)\n",
        "    output1 = layer1(input)\n",
        "    output2 = layer2(output1)\n",
        "\n",
        "    self.assertEqual(output1.shape, (1, 128, 64, 32))\n",
        "    self.assertEqual(output2.shape, (1, 256, 64, 32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCQtsPSjtdvl"
      },
      "source": [
        "### TestOSNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUxxDuFEI66z"
      },
      "source": [
        "class TestOSNet(unittest.TestCase):\n",
        "  def test_ouput(self):\n",
        "    model = OSNet(num_classes=10)\n",
        "\n",
        "    batch_size = 2\n",
        "    input = torch.randn(2, 3, 256, 128)\n",
        "    stage1 = model.conv1(input)\n",
        "    stage1 = model.maxpool(stage1)\n",
        "\n",
        "    stage2 = model.conv2(stage1)\n",
        "    stage2 = model.tran1(stage2)\n",
        "\n",
        "    stage3 = model.conv3(stage2)\n",
        "    stage3 = model.tran2(stage3)\n",
        "\n",
        "    stage4 = model.conv4(stage3)\n",
        "    stage5 = model.conv5(stage4)\n",
        "\n",
        "    feature = model.featuremaps(input)\n",
        "    output = model(input)\n",
        "\n",
        "    self.assertEqual(model.loss, 'softmax')\n",
        "    self.assertEqual(stage1.shape, (batch_size, 64, 64, 32))\n",
        "    self.assertEqual(stage2.shape, (batch_size, 256, 32, 16))\n",
        "    self.assertEqual(stage3.shape, (batch_size, 384, 16, 8))\n",
        "    self.assertEqual(stage4.shape, (batch_size, 512, 16, 8))\n",
        "    self.assertEqual(stage5.shape, (batch_size, 512, 16, 8))\n",
        "    self.assertEqual(feature.shape, stage5.shape)\n",
        "    self.assertEqual(output.shape, (batch_size, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-CLi5Mk567l"
      },
      "source": [
        "# Run test âœ”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qU9Zvny5-ks",
        "outputId": "06538ffa-727e-452a-b95f-5da5e4341919"
      },
      "source": [
        "unittest.main(argv=[''], verbosity=2, exit=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "test_ouput (__main__.TestConv1x1) ... ok\n",
            "test_ouput (__main__.TestConvLayer) ... ok\n",
            "test_ouput (__main__.TestLightConv3x3) ... ok\n",
            "test_ouput (__main__.TestOSNet) ... ok\n",
            "test_ouput (__main__.TestOSResBlock) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 5 tests in 1.096s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7ff9abf42ed0>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq12FDTLgNoD"
      },
      "source": [
        "# Training âœ”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j57r4w6igSCE",
        "outputId": "76bad425-a272-4c1d-b043-d40e6b8ff45e"
      },
      "source": [
        "def train_epoch(epoch, model, trainloader, criterion, optimizer, print_freq = 10, use_gpu = True):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "\n",
        "    for batch_index, data in enumerate(trainloader):\n",
        "      loss, acc = forward_backward(model, data, criterion, optimizer, use_gpu)\n",
        "\n",
        "      running_loss += loss\n",
        "      running_acc += acc\n",
        "      if (batch_index + 1) % print_freq == 0:\n",
        "        print('[%d, %5d]\\t loss: %.3f\\t accuracy: %.3f' \n",
        "              %(epoch + 1, batch_index + 1, running_loss / print_freq, running_acc / print_freq))\n",
        "        running_loss = 0.0\n",
        "        running_acc  = 0.0\n",
        "\n",
        "def forward_backward(model, data, criterion, optimizer, use_gpu = True):\n",
        "    imgs, pids = parse_data_for_train(data)\n",
        "    \n",
        "    if use_gpu:\n",
        "        imgs, pids = imgs.cuda(), pids.cuda()\n",
        "\n",
        "    logits = model(imgs)\n",
        "    loss = criterion(logits, pids)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    \n",
        "    _, prediction = torch.max(logits, dim=1)\n",
        "    acc = (prediction == pids).sum() * 100 / len(pids)\n",
        "    \n",
        "    return loss.item(), acc.item()\n",
        "\n",
        "def parse_data_for_train(data):\n",
        "    imgs = data['img']\n",
        "    pids = data['pid']\n",
        "    return imgs, pids\n",
        "\n",
        "def main(max_epoch = 15, print_freq = 10, use_gpu = True):\n",
        "    data_preparer = DataPreparer(root='./data')\n",
        "\n",
        "    if torch.cuda.is_available() == False:\n",
        "       use_gpu = False\n",
        "\n",
        "    model = OSNet(num_classes = data_preparer.num_train_pids)\n",
        "    if use_gpu:\n",
        "       model = model.cuda()\n",
        "\n",
        "    criterion = CrossEntropyLoss(num_classes = data_preparer.num_train_pids)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "    for epoch in range(max_epoch):\n",
        "        train_epoch(    \n",
        "            epoch = epoch,\n",
        "            model=model,\n",
        "            trainloader = data_preparer.trainloader,\n",
        "            criterion = criterion,\n",
        "            optimizer = optimizer,\n",
        "            print_freq=print_freq,\n",
        "            use_gpu=use_gpu\n",
        "        )\n",
        "        torch.save(model.state_dict(), './pretrained_model.pth')\n",
        "\n",
        "main(use_gpu = True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Loading train (source) dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,    10]\t loss: 6.708\t accuracy: 0.000\n",
            "[1,    20]\t loss: 6.654\t accuracy: 0.625\n",
            "[1,    30]\t loss: 6.636\t accuracy: 1.250\n",
            "[1,    40]\t loss: 6.547\t accuracy: 0.938\n",
            "[1,    50]\t loss: 6.516\t accuracy: 0.938\n",
            "[1,    60]\t loss: 6.529\t accuracy: 1.562\n",
            "[1,    70]\t loss: 6.506\t accuracy: 1.250\n",
            "[1,    80]\t loss: 6.400\t accuracy: 1.250\n",
            "[1,    90]\t loss: 6.471\t accuracy: 0.625\n",
            "[1,   100]\t loss: 6.425\t accuracy: 0.938\n",
            "[1,   110]\t loss: 6.365\t accuracy: 0.312\n",
            "[1,   120]\t loss: 6.322\t accuracy: 0.938\n",
            "[1,   130]\t loss: 6.300\t accuracy: 1.562\n",
            "[1,   140]\t loss: 6.321\t accuracy: 0.312\n",
            "[1,   150]\t loss: 6.276\t accuracy: 1.250\n",
            "[1,   160]\t loss: 6.238\t accuracy: 1.562\n",
            "[1,   170]\t loss: 6.211\t accuracy: 1.562\n",
            "[1,   180]\t loss: 6.135\t accuracy: 2.188\n",
            "[1,   190]\t loss: 6.122\t accuracy: 3.438\n",
            "[1,   200]\t loss: 6.199\t accuracy: 1.250\n",
            "[1,   210]\t loss: 6.137\t accuracy: 1.250\n",
            "[1,   220]\t loss: 6.081\t accuracy: 2.188\n",
            "[1,   230]\t loss: 6.008\t accuracy: 1.562\n",
            "[1,   240]\t loss: 5.987\t accuracy: 2.500\n",
            "[1,   250]\t loss: 6.019\t accuracy: 2.812\n",
            "[1,   260]\t loss: 5.981\t accuracy: 4.375\n",
            "[1,   270]\t loss: 5.997\t accuracy: 5.000\n",
            "[1,   280]\t loss: 5.771\t accuracy: 4.688\n",
            "[1,   290]\t loss: 5.821\t accuracy: 3.438\n",
            "[1,   300]\t loss: 5.845\t accuracy: 4.062\n",
            "[1,   310]\t loss: 5.843\t accuracy: 1.875\n",
            "[1,   320]\t loss: 5.807\t accuracy: 4.688\n",
            "[1,   330]\t loss: 5.805\t accuracy: 4.688\n",
            "[1,   340]\t loss: 5.748\t accuracy: 2.812\n",
            "[1,   350]\t loss: 5.726\t accuracy: 3.750\n",
            "[1,   360]\t loss: 5.830\t accuracy: 2.188\n",
            "[1,   370]\t loss: 5.711\t accuracy: 4.062\n",
            "[1,   380]\t loss: 5.533\t accuracy: 6.250\n",
            "[1,   390]\t loss: 5.518\t accuracy: 5.938\n",
            "[1,   400]\t loss: 5.554\t accuracy: 6.562\n",
            "[2,    10]\t loss: 5.416\t accuracy: 6.562\n",
            "[2,    20]\t loss: 5.417\t accuracy: 5.625\n",
            "[2,    30]\t loss: 5.333\t accuracy: 7.812\n",
            "[2,    40]\t loss: 5.311\t accuracy: 8.125\n",
            "[2,    50]\t loss: 5.306\t accuracy: 6.875\n",
            "[2,    60]\t loss: 5.366\t accuracy: 8.125\n",
            "[2,    70]\t loss: 5.218\t accuracy: 6.562\n",
            "[2,    80]\t loss: 5.270\t accuracy: 7.812\n",
            "[2,    90]\t loss: 5.247\t accuracy: 9.688\n",
            "[2,   100]\t loss: 5.215\t accuracy: 8.750\n",
            "[2,   110]\t loss: 5.185\t accuracy: 10.625\n",
            "[2,   120]\t loss: 5.146\t accuracy: 11.562\n",
            "[2,   130]\t loss: 5.119\t accuracy: 10.000\n",
            "[2,   140]\t loss: 5.088\t accuracy: 10.000\n",
            "[2,   150]\t loss: 5.049\t accuracy: 10.938\n",
            "[2,   160]\t loss: 5.100\t accuracy: 10.312\n",
            "[2,   170]\t loss: 5.002\t accuracy: 9.375\n",
            "[2,   180]\t loss: 4.894\t accuracy: 12.188\n",
            "[2,   190]\t loss: 5.021\t accuracy: 12.500\n",
            "[2,   200]\t loss: 4.970\t accuracy: 10.938\n",
            "[2,   210]\t loss: 4.937\t accuracy: 13.125\n",
            "[2,   220]\t loss: 4.859\t accuracy: 13.125\n",
            "[2,   230]\t loss: 4.936\t accuracy: 11.875\n",
            "[2,   240]\t loss: 4.701\t accuracy: 14.688\n",
            "[2,   250]\t loss: 4.773\t accuracy: 12.812\n",
            "[2,   260]\t loss: 4.686\t accuracy: 17.188\n",
            "[2,   270]\t loss: 4.919\t accuracy: 10.938\n",
            "[2,   280]\t loss: 4.534\t accuracy: 18.750\n",
            "[2,   290]\t loss: 4.696\t accuracy: 13.125\n",
            "[2,   300]\t loss: 4.670\t accuracy: 18.125\n",
            "[2,   310]\t loss: 4.649\t accuracy: 17.812\n",
            "[2,   320]\t loss: 4.671\t accuracy: 15.938\n",
            "[2,   330]\t loss: 4.608\t accuracy: 14.688\n",
            "[2,   340]\t loss: 4.513\t accuracy: 20.625\n",
            "[2,   350]\t loss: 4.582\t accuracy: 14.688\n",
            "[2,   360]\t loss: 4.531\t accuracy: 16.875\n",
            "[2,   370]\t loss: 4.464\t accuracy: 18.438\n",
            "[2,   380]\t loss: 4.391\t accuracy: 20.625\n",
            "[2,   390]\t loss: 4.402\t accuracy: 24.062\n",
            "[2,   400]\t loss: 4.510\t accuracy: 19.375\n",
            "[3,    10]\t loss: 4.216\t accuracy: 24.062\n",
            "[3,    20]\t loss: 4.303\t accuracy: 15.312\n",
            "[3,    30]\t loss: 4.205\t accuracy: 25.312\n",
            "[3,    40]\t loss: 4.005\t accuracy: 25.938\n",
            "[3,    50]\t loss: 4.121\t accuracy: 25.938\n",
            "[3,    60]\t loss: 4.170\t accuracy: 22.500\n",
            "[3,    70]\t loss: 4.153\t accuracy: 21.562\n",
            "[3,    80]\t loss: 3.973\t accuracy: 26.250\n",
            "[3,    90]\t loss: 4.058\t accuracy: 25.938\n",
            "[3,   100]\t loss: 4.132\t accuracy: 23.750\n",
            "[3,   110]\t loss: 4.101\t accuracy: 25.625\n",
            "[3,   120]\t loss: 3.970\t accuracy: 26.250\n",
            "[3,   130]\t loss: 4.160\t accuracy: 22.500\n",
            "[3,   140]\t loss: 3.995\t accuracy: 26.250\n",
            "[3,   150]\t loss: 3.943\t accuracy: 30.625\n",
            "[3,   160]\t loss: 3.979\t accuracy: 27.500\n",
            "[3,   170]\t loss: 3.954\t accuracy: 27.500\n",
            "[3,   180]\t loss: 3.773\t accuracy: 33.438\n",
            "[3,   190]\t loss: 3.772\t accuracy: 33.125\n",
            "[3,   200]\t loss: 3.817\t accuracy: 30.625\n",
            "[3,   210]\t loss: 3.873\t accuracy: 29.062\n",
            "[3,   220]\t loss: 3.829\t accuracy: 30.000\n",
            "[3,   230]\t loss: 3.930\t accuracy: 28.438\n",
            "[3,   240]\t loss: 3.871\t accuracy: 30.625\n",
            "[3,   250]\t loss: 3.818\t accuracy: 30.625\n",
            "[3,   260]\t loss: 3.756\t accuracy: 32.812\n",
            "[3,   270]\t loss: 3.711\t accuracy: 32.500\n",
            "[3,   280]\t loss: 3.575\t accuracy: 39.375\n",
            "[3,   290]\t loss: 3.617\t accuracy: 38.125\n",
            "[3,   300]\t loss: 3.733\t accuracy: 32.500\n",
            "[3,   310]\t loss: 3.650\t accuracy: 36.562\n",
            "[3,   320]\t loss: 3.586\t accuracy: 34.688\n",
            "[3,   330]\t loss: 3.689\t accuracy: 34.375\n",
            "[3,   340]\t loss: 3.705\t accuracy: 32.188\n",
            "[3,   350]\t loss: 3.623\t accuracy: 35.938\n",
            "[3,   360]\t loss: 3.568\t accuracy: 35.312\n",
            "[3,   370]\t loss: 3.674\t accuracy: 37.812\n",
            "[3,   380]\t loss: 3.545\t accuracy: 39.062\n",
            "[3,   390]\t loss: 3.306\t accuracy: 40.625\n",
            "[3,   400]\t loss: 3.564\t accuracy: 35.000\n",
            "[4,    10]\t loss: 3.186\t accuracy: 43.438\n",
            "[4,    20]\t loss: 3.335\t accuracy: 38.438\n",
            "[4,    30]\t loss: 3.303\t accuracy: 44.688\n",
            "[4,    40]\t loss: 3.312\t accuracy: 39.375\n",
            "[4,    50]\t loss: 3.173\t accuracy: 46.562\n",
            "[4,    60]\t loss: 3.090\t accuracy: 47.500\n",
            "[4,    70]\t loss: 3.156\t accuracy: 44.688\n",
            "[4,    80]\t loss: 3.324\t accuracy: 40.000\n",
            "[4,    90]\t loss: 3.086\t accuracy: 48.438\n",
            "[4,   100]\t loss: 3.158\t accuracy: 45.000\n",
            "[4,   110]\t loss: 3.233\t accuracy: 43.750\n",
            "[4,   120]\t loss: 3.090\t accuracy: 52.500\n",
            "[4,   130]\t loss: 3.040\t accuracy: 52.500\n",
            "[4,   140]\t loss: 3.294\t accuracy: 41.875\n",
            "[4,   150]\t loss: 3.104\t accuracy: 47.500\n",
            "[4,   160]\t loss: 3.146\t accuracy: 44.688\n",
            "[4,   170]\t loss: 3.175\t accuracy: 47.188\n",
            "[4,   180]\t loss: 2.986\t accuracy: 47.812\n",
            "[4,   190]\t loss: 3.048\t accuracy: 45.938\n",
            "[4,   200]\t loss: 3.030\t accuracy: 51.562\n",
            "[4,   210]\t loss: 2.945\t accuracy: 55.312\n",
            "[4,   220]\t loss: 2.989\t accuracy: 51.562\n",
            "[4,   230]\t loss: 3.075\t accuracy: 48.125\n",
            "[4,   240]\t loss: 2.942\t accuracy: 54.688\n",
            "[4,   250]\t loss: 2.987\t accuracy: 50.625\n",
            "[4,   260]\t loss: 2.962\t accuracy: 52.500\n",
            "[4,   270]\t loss: 3.100\t accuracy: 46.875\n",
            "[4,   280]\t loss: 2.997\t accuracy: 48.125\n",
            "[4,   290]\t loss: 2.894\t accuracy: 52.188\n",
            "[4,   300]\t loss: 2.922\t accuracy: 53.438\n",
            "[4,   310]\t loss: 2.762\t accuracy: 55.625\n",
            "[4,   320]\t loss: 2.895\t accuracy: 54.375\n",
            "[4,   330]\t loss: 2.782\t accuracy: 57.500\n",
            "[4,   340]\t loss: 2.816\t accuracy: 56.250\n",
            "[4,   350]\t loss: 2.735\t accuracy: 56.875\n",
            "[4,   360]\t loss: 2.826\t accuracy: 55.312\n",
            "[4,   370]\t loss: 2.845\t accuracy: 53.750\n",
            "[4,   380]\t loss: 2.795\t accuracy: 57.188\n",
            "[4,   390]\t loss: 2.821\t accuracy: 52.812\n",
            "[4,   400]\t loss: 2.706\t accuracy: 56.875\n",
            "[5,    10]\t loss: 2.497\t accuracy: 67.188\n",
            "[5,    20]\t loss: 2.594\t accuracy: 59.062\n",
            "[5,    30]\t loss: 2.630\t accuracy: 60.000\n",
            "[5,    40]\t loss: 2.625\t accuracy: 59.688\n",
            "[5,    50]\t loss: 2.631\t accuracy: 62.500\n",
            "[5,    60]\t loss: 2.499\t accuracy: 67.188\n",
            "[5,    70]\t loss: 2.508\t accuracy: 64.688\n",
            "[5,    80]\t loss: 2.445\t accuracy: 68.750\n",
            "[5,    90]\t loss: 2.480\t accuracy: 65.938\n",
            "[5,   100]\t loss: 2.576\t accuracy: 60.625\n",
            "[5,   110]\t loss: 2.489\t accuracy: 63.750\n",
            "[5,   120]\t loss: 2.504\t accuracy: 68.438\n",
            "[5,   130]\t loss: 2.451\t accuracy: 66.562\n",
            "[5,   140]\t loss: 2.482\t accuracy: 65.312\n",
            "[5,   150]\t loss: 2.454\t accuracy: 65.000\n",
            "[5,   160]\t loss: 2.467\t accuracy: 65.000\n",
            "[5,   170]\t loss: 2.254\t accuracy: 71.875\n",
            "[5,   180]\t loss: 2.388\t accuracy: 68.125\n",
            "[5,   190]\t loss: 2.504\t accuracy: 61.562\n",
            "[5,   200]\t loss: 2.457\t accuracy: 64.062\n",
            "[5,   210]\t loss: 2.388\t accuracy: 67.500\n",
            "[5,   220]\t loss: 2.572\t accuracy: 60.938\n",
            "[5,   230]\t loss: 2.292\t accuracy: 72.812\n",
            "[5,   240]\t loss: 2.475\t accuracy: 66.875\n",
            "[5,   250]\t loss: 2.447\t accuracy: 66.250\n",
            "[5,   260]\t loss: 2.471\t accuracy: 65.000\n",
            "[5,   270]\t loss: 2.355\t accuracy: 67.188\n",
            "[5,   280]\t loss: 2.284\t accuracy: 71.875\n",
            "[5,   290]\t loss: 2.357\t accuracy: 68.438\n",
            "[5,   300]\t loss: 2.320\t accuracy: 67.812\n",
            "[5,   310]\t loss: 2.358\t accuracy: 67.500\n",
            "[5,   320]\t loss: 2.324\t accuracy: 69.375\n",
            "[5,   330]\t loss: 2.243\t accuracy: 69.688\n",
            "[5,   340]\t loss: 2.553\t accuracy: 61.562\n",
            "[5,   350]\t loss: 2.406\t accuracy: 67.500\n",
            "[5,   360]\t loss: 2.419\t accuracy: 65.625\n",
            "[5,   370]\t loss: 2.339\t accuracy: 69.688\n",
            "[5,   380]\t loss: 2.322\t accuracy: 70.938\n",
            "[5,   390]\t loss: 2.202\t accuracy: 73.750\n",
            "[5,   400]\t loss: 2.318\t accuracy: 67.500\n",
            "[6,    10]\t loss: 2.125\t accuracy: 77.500\n",
            "[6,    20]\t loss: 2.073\t accuracy: 78.438\n",
            "[6,    30]\t loss: 2.075\t accuracy: 74.062\n",
            "[6,    40]\t loss: 2.065\t accuracy: 78.125\n",
            "[6,    50]\t loss: 2.138\t accuracy: 74.688\n",
            "[6,    60]\t loss: 2.186\t accuracy: 71.250\n",
            "[6,    70]\t loss: 2.156\t accuracy: 73.438\n",
            "[6,    80]\t loss: 2.169\t accuracy: 72.500\n",
            "[6,    90]\t loss: 2.059\t accuracy: 75.312\n",
            "[6,   100]\t loss: 2.071\t accuracy: 77.500\n",
            "[6,   110]\t loss: 2.087\t accuracy: 77.188\n",
            "[6,   120]\t loss: 2.005\t accuracy: 77.188\n",
            "[6,   130]\t loss: 2.111\t accuracy: 73.750\n",
            "[6,   140]\t loss: 2.077\t accuracy: 78.125\n",
            "[6,   150]\t loss: 2.123\t accuracy: 74.062\n",
            "[6,   160]\t loss: 2.072\t accuracy: 77.188\n",
            "[6,   170]\t loss: 2.102\t accuracy: 76.562\n",
            "[6,   180]\t loss: 2.023\t accuracy: 77.812\n",
            "[6,   190]\t loss: 1.995\t accuracy: 80.625\n",
            "[6,   200]\t loss: 2.161\t accuracy: 76.250\n",
            "[6,   210]\t loss: 2.035\t accuracy: 78.750\n",
            "[6,   220]\t loss: 2.034\t accuracy: 79.375\n",
            "[6,   230]\t loss: 2.019\t accuracy: 78.125\n",
            "[6,   240]\t loss: 1.976\t accuracy: 83.438\n",
            "[6,   250]\t loss: 2.007\t accuracy: 78.750\n",
            "[6,   260]\t loss: 2.040\t accuracy: 77.500\n",
            "[6,   270]\t loss: 2.020\t accuracy: 80.000\n",
            "[6,   280]\t loss: 2.041\t accuracy: 79.062\n",
            "[6,   290]\t loss: 1.976\t accuracy: 81.875\n",
            "[6,   300]\t loss: 1.967\t accuracy: 81.875\n",
            "[6,   310]\t loss: 2.029\t accuracy: 78.750\n",
            "[6,   320]\t loss: 2.015\t accuracy: 78.125\n",
            "[6,   330]\t loss: 1.954\t accuracy: 80.312\n",
            "[6,   340]\t loss: 1.959\t accuracy: 78.438\n",
            "[6,   350]\t loss: 1.835\t accuracy: 85.625\n",
            "[6,   360]\t loss: 1.974\t accuracy: 77.188\n",
            "[6,   370]\t loss: 1.993\t accuracy: 80.000\n",
            "[6,   380]\t loss: 1.900\t accuracy: 82.500\n",
            "[6,   390]\t loss: 2.004\t accuracy: 80.312\n",
            "[6,   400]\t loss: 1.893\t accuracy: 82.812\n",
            "[7,    10]\t loss: 1.786\t accuracy: 86.250\n",
            "[7,    20]\t loss: 1.745\t accuracy: 87.500\n",
            "[7,    30]\t loss: 1.877\t accuracy: 82.812\n",
            "[7,    40]\t loss: 1.806\t accuracy: 85.625\n",
            "[7,    50]\t loss: 1.727\t accuracy: 89.375\n",
            "[7,    60]\t loss: 1.815\t accuracy: 86.562\n",
            "[7,    70]\t loss: 1.773\t accuracy: 87.188\n",
            "[7,    80]\t loss: 1.814\t accuracy: 86.875\n",
            "[7,    90]\t loss: 1.787\t accuracy: 86.875\n",
            "[7,   100]\t loss: 1.747\t accuracy: 86.875\n",
            "[7,   110]\t loss: 1.758\t accuracy: 87.500\n",
            "[7,   120]\t loss: 1.816\t accuracy: 84.375\n",
            "[7,   130]\t loss: 1.844\t accuracy: 83.438\n",
            "[7,   140]\t loss: 1.827\t accuracy: 84.062\n",
            "[7,   150]\t loss: 1.781\t accuracy: 85.938\n",
            "[7,   160]\t loss: 1.838\t accuracy: 83.750\n",
            "[7,   170]\t loss: 1.780\t accuracy: 88.750\n",
            "[7,   180]\t loss: 1.838\t accuracy: 80.312\n",
            "[7,   190]\t loss: 1.757\t accuracy: 89.375\n",
            "[7,   200]\t loss: 1.739\t accuracy: 86.562\n",
            "[7,   210]\t loss: 1.781\t accuracy: 86.875\n",
            "[7,   220]\t loss: 1.724\t accuracy: 88.438\n",
            "[7,   230]\t loss: 1.736\t accuracy: 87.812\n",
            "[7,   240]\t loss: 1.783\t accuracy: 85.625\n",
            "[7,   250]\t loss: 1.700\t accuracy: 87.188\n",
            "[7,   260]\t loss: 1.719\t accuracy: 89.062\n",
            "[7,   270]\t loss: 1.810\t accuracy: 85.938\n",
            "[7,   280]\t loss: 1.771\t accuracy: 84.062\n",
            "[7,   290]\t loss: 1.730\t accuracy: 89.688\n",
            "[7,   300]\t loss: 1.717\t accuracy: 86.250\n",
            "[7,   310]\t loss: 1.763\t accuracy: 86.250\n",
            "[7,   320]\t loss: 1.704\t accuracy: 88.438\n",
            "[7,   330]\t loss: 1.870\t accuracy: 82.500\n",
            "[7,   340]\t loss: 1.758\t accuracy: 86.250\n",
            "[7,   350]\t loss: 1.761\t accuracy: 86.875\n",
            "[7,   360]\t loss: 1.857\t accuracy: 83.125\n",
            "[7,   370]\t loss: 1.861\t accuracy: 82.188\n",
            "[7,   380]\t loss: 1.804\t accuracy: 83.750\n",
            "[7,   390]\t loss: 1.681\t accuracy: 89.688\n",
            "[7,   400]\t loss: 1.736\t accuracy: 87.500\n",
            "[8,    10]\t loss: 1.583\t accuracy: 92.188\n",
            "[8,    20]\t loss: 1.646\t accuracy: 87.188\n",
            "[8,    30]\t loss: 1.607\t accuracy: 91.250\n",
            "[8,    40]\t loss: 1.672\t accuracy: 89.062\n",
            "[8,    50]\t loss: 1.636\t accuracy: 90.625\n",
            "[8,    60]\t loss: 1.607\t accuracy: 92.812\n",
            "[8,    70]\t loss: 1.592\t accuracy: 90.625\n",
            "[8,    80]\t loss: 1.582\t accuracy: 93.750\n",
            "[8,    90]\t loss: 1.634\t accuracy: 89.688\n",
            "[8,   100]\t loss: 1.618\t accuracy: 91.250\n",
            "[8,   110]\t loss: 1.631\t accuracy: 91.250\n",
            "[8,   120]\t loss: 1.598\t accuracy: 90.625\n",
            "[8,   130]\t loss: 1.659\t accuracy: 89.375\n",
            "[8,   140]\t loss: 1.631\t accuracy: 91.250\n",
            "[8,   150]\t loss: 1.631\t accuracy: 90.000\n",
            "[8,   160]\t loss: 1.629\t accuracy: 90.625\n",
            "[8,   170]\t loss: 1.580\t accuracy: 92.812\n",
            "[8,   180]\t loss: 1.603\t accuracy: 91.250\n",
            "[8,   190]\t loss: 1.567\t accuracy: 91.250\n",
            "[8,   200]\t loss: 1.626\t accuracy: 89.688\n",
            "[8,   210]\t loss: 1.581\t accuracy: 92.812\n",
            "[8,   220]\t loss: 1.600\t accuracy: 91.562\n",
            "[8,   230]\t loss: 1.616\t accuracy: 92.812\n",
            "[8,   240]\t loss: 1.567\t accuracy: 91.875\n",
            "[8,   250]\t loss: 1.605\t accuracy: 90.625\n",
            "[8,   260]\t loss: 1.632\t accuracy: 88.750\n",
            "[8,   270]\t loss: 1.552\t accuracy: 91.875\n",
            "[8,   280]\t loss: 1.629\t accuracy: 87.188\n",
            "[8,   290]\t loss: 1.624\t accuracy: 92.188\n",
            "[8,   300]\t loss: 1.612\t accuracy: 91.875\n",
            "[8,   310]\t loss: 1.659\t accuracy: 91.562\n",
            "[8,   320]\t loss: 1.656\t accuracy: 90.000\n",
            "[8,   330]\t loss: 1.602\t accuracy: 93.125\n",
            "[8,   340]\t loss: 1.608\t accuracy: 91.250\n",
            "[8,   350]\t loss: 1.617\t accuracy: 91.250\n",
            "[8,   360]\t loss: 1.606\t accuracy: 90.000\n",
            "[8,   370]\t loss: 1.617\t accuracy: 89.688\n",
            "[8,   380]\t loss: 1.654\t accuracy: 89.062\n",
            "[8,   390]\t loss: 1.566\t accuracy: 92.500\n",
            "[8,   400]\t loss: 1.601\t accuracy: 91.250\n",
            "[9,    10]\t loss: 1.501\t accuracy: 93.750\n",
            "[9,    20]\t loss: 1.580\t accuracy: 91.250\n",
            "[9,    30]\t loss: 1.487\t accuracy: 94.688\n",
            "[9,    40]\t loss: 1.468\t accuracy: 95.312\n",
            "[9,    50]\t loss: 1.465\t accuracy: 96.875\n",
            "[9,    60]\t loss: 1.509\t accuracy: 93.438\n",
            "[9,    70]\t loss: 1.510\t accuracy: 95.000\n",
            "[9,    80]\t loss: 1.483\t accuracy: 95.000\n",
            "[9,    90]\t loss: 1.487\t accuracy: 95.000\n",
            "[9,   100]\t loss: 1.488\t accuracy: 94.375\n",
            "[9,   110]\t loss: 1.479\t accuracy: 94.688\n",
            "[9,   120]\t loss: 1.478\t accuracy: 95.312\n",
            "[9,   130]\t loss: 1.491\t accuracy: 95.938\n",
            "[9,   140]\t loss: 1.504\t accuracy: 94.688\n",
            "[9,   150]\t loss: 1.457\t accuracy: 96.562\n",
            "[9,   160]\t loss: 1.478\t accuracy: 94.375\n",
            "[9,   170]\t loss: 1.493\t accuracy: 94.688\n",
            "[9,   180]\t loss: 1.481\t accuracy: 94.375\n",
            "[9,   190]\t loss: 1.474\t accuracy: 95.312\n",
            "[9,   200]\t loss: 1.456\t accuracy: 94.375\n",
            "[9,   210]\t loss: 1.457\t accuracy: 95.625\n",
            "[9,   220]\t loss: 1.472\t accuracy: 95.938\n",
            "[9,   230]\t loss: 1.490\t accuracy: 95.000\n",
            "[9,   240]\t loss: 1.487\t accuracy: 95.000\n",
            "[9,   250]\t loss: 1.467\t accuracy: 94.375\n",
            "[9,   260]\t loss: 1.459\t accuracy: 95.000\n",
            "[9,   270]\t loss: 1.501\t accuracy: 94.062\n",
            "[9,   280]\t loss: 1.494\t accuracy: 95.000\n",
            "[9,   290]\t loss: 1.542\t accuracy: 90.938\n",
            "[9,   300]\t loss: 1.475\t accuracy: 95.938\n",
            "[9,   310]\t loss: 1.508\t accuracy: 93.750\n",
            "[9,   320]\t loss: 1.434\t accuracy: 95.625\n",
            "[9,   330]\t loss: 1.464\t accuracy: 95.625\n",
            "[9,   340]\t loss: 1.513\t accuracy: 92.812\n",
            "[9,   350]\t loss: 1.522\t accuracy: 92.188\n",
            "[9,   360]\t loss: 1.461\t accuracy: 95.000\n",
            "[9,   370]\t loss: 1.540\t accuracy: 91.562\n",
            "[9,   380]\t loss: 1.489\t accuracy: 93.125\n",
            "[9,   390]\t loss: 1.482\t accuracy: 95.312\n",
            "[9,   400]\t loss: 1.486\t accuracy: 93.438\n",
            "[10,    10]\t loss: 1.381\t accuracy: 97.500\n",
            "[10,    20]\t loss: 1.429\t accuracy: 96.250\n",
            "[10,    30]\t loss: 1.410\t accuracy: 97.500\n",
            "[10,    40]\t loss: 1.403\t accuracy: 97.188\n",
            "[10,    50]\t loss: 1.415\t accuracy: 94.688\n",
            "[10,    60]\t loss: 1.369\t accuracy: 97.500\n",
            "[10,    70]\t loss: 1.408\t accuracy: 96.250\n",
            "[10,    80]\t loss: 1.411\t accuracy: 96.562\n",
            "[10,    90]\t loss: 1.390\t accuracy: 97.500\n",
            "[10,   100]\t loss: 1.408\t accuracy: 97.500\n",
            "[10,   110]\t loss: 1.408\t accuracy: 96.875\n",
            "[10,   120]\t loss: 1.389\t accuracy: 97.188\n",
            "[10,   130]\t loss: 1.402\t accuracy: 97.812\n",
            "[10,   140]\t loss: 1.376\t accuracy: 97.188\n",
            "[10,   150]\t loss: 1.394\t accuracy: 97.812\n",
            "[10,   160]\t loss: 1.455\t accuracy: 94.062\n",
            "[10,   170]\t loss: 1.400\t accuracy: 98.125\n",
            "[10,   180]\t loss: 1.400\t accuracy: 96.875\n",
            "[10,   190]\t loss: 1.405\t accuracy: 95.938\n",
            "[10,   200]\t loss: 1.390\t accuracy: 97.500\n",
            "[10,   210]\t loss: 1.430\t accuracy: 96.250\n",
            "[10,   220]\t loss: 1.411\t accuracy: 97.500\n",
            "[10,   230]\t loss: 1.441\t accuracy: 95.938\n",
            "[10,   240]\t loss: 1.447\t accuracy: 95.000\n",
            "[10,   250]\t loss: 1.418\t accuracy: 96.562\n",
            "[10,   260]\t loss: 1.443\t accuracy: 96.562\n",
            "[10,   270]\t loss: 1.450\t accuracy: 95.000\n",
            "[10,   280]\t loss: 1.354\t accuracy: 98.750\n",
            "[10,   290]\t loss: 1.374\t accuracy: 97.188\n",
            "[10,   300]\t loss: 1.436\t accuracy: 95.312\n",
            "[10,   310]\t loss: 1.436\t accuracy: 95.938\n",
            "[10,   320]\t loss: 1.430\t accuracy: 95.312\n",
            "[10,   330]\t loss: 1.441\t accuracy: 95.625\n",
            "[10,   340]\t loss: 1.424\t accuracy: 95.625\n",
            "[10,   350]\t loss: 1.415\t accuracy: 96.250\n",
            "[10,   360]\t loss: 1.421\t accuracy: 96.562\n",
            "[10,   370]\t loss: 1.427\t accuracy: 94.375\n",
            "[10,   380]\t loss: 1.370\t accuracy: 98.125\n",
            "[10,   390]\t loss: 1.421\t accuracy: 95.312\n",
            "[10,   400]\t loss: 1.437\t accuracy: 93.125\n",
            "[11,    10]\t loss: 1.345\t accuracy: 97.812\n",
            "[11,    20]\t loss: 1.320\t accuracy: 97.188\n",
            "[11,    30]\t loss: 1.352\t accuracy: 96.562\n",
            "[11,    40]\t loss: 1.330\t accuracy: 98.438\n",
            "[11,    50]\t loss: 1.334\t accuracy: 98.750\n",
            "[11,    60]\t loss: 1.340\t accuracy: 98.125\n",
            "[11,    70]\t loss: 1.322\t accuracy: 98.750\n",
            "[11,    80]\t loss: 1.314\t accuracy: 98.438\n",
            "[11,    90]\t loss: 1.321\t accuracy: 97.812\n",
            "[11,   100]\t loss: 1.332\t accuracy: 98.125\n",
            "[11,   110]\t loss: 1.329\t accuracy: 97.812\n",
            "[11,   120]\t loss: 1.324\t accuracy: 99.062\n",
            "[11,   130]\t loss: 1.317\t accuracy: 98.750\n",
            "[11,   140]\t loss: 1.323\t accuracy: 97.500\n",
            "[11,   150]\t loss: 1.329\t accuracy: 97.500\n",
            "[11,   160]\t loss: 1.339\t accuracy: 97.812\n",
            "[11,   170]\t loss: 1.332\t accuracy: 98.125\n",
            "[11,   180]\t loss: 1.349\t accuracy: 97.812\n",
            "[11,   190]\t loss: 1.370\t accuracy: 95.938\n",
            "[11,   200]\t loss: 1.380\t accuracy: 96.250\n",
            "[11,   210]\t loss: 1.359\t accuracy: 96.875\n",
            "[11,   220]\t loss: 1.358\t accuracy: 96.875\n",
            "[11,   230]\t loss: 1.337\t accuracy: 97.812\n",
            "[11,   240]\t loss: 1.383\t accuracy: 96.562\n",
            "[11,   250]\t loss: 1.369\t accuracy: 97.188\n",
            "[11,   260]\t loss: 1.337\t accuracy: 98.125\n",
            "[11,   270]\t loss: 1.372\t accuracy: 95.000\n",
            "[11,   280]\t loss: 1.346\t accuracy: 97.812\n",
            "[11,   290]\t loss: 1.368\t accuracy: 97.500\n",
            "[11,   300]\t loss: 1.400\t accuracy: 95.312\n",
            "[11,   310]\t loss: 1.381\t accuracy: 95.000\n",
            "[11,   320]\t loss: 1.351\t accuracy: 97.500\n",
            "[11,   330]\t loss: 1.356\t accuracy: 97.500\n",
            "[11,   340]\t loss: 1.360\t accuracy: 96.875\n",
            "[11,   350]\t loss: 1.372\t accuracy: 96.562\n",
            "[11,   360]\t loss: 1.354\t accuracy: 98.438\n",
            "[11,   370]\t loss: 1.321\t accuracy: 99.375\n",
            "[11,   380]\t loss: 1.341\t accuracy: 96.562\n",
            "[11,   390]\t loss: 1.365\t accuracy: 96.250\n",
            "[11,   400]\t loss: 1.376\t accuracy: 98.125\n",
            "[12,    10]\t loss: 1.293\t accuracy: 99.062\n",
            "[12,    20]\t loss: 1.304\t accuracy: 96.875\n",
            "[12,    30]\t loss: 1.299\t accuracy: 99.062\n",
            "[12,    40]\t loss: 1.288\t accuracy: 98.438\n",
            "[12,    50]\t loss: 1.264\t accuracy: 99.062\n",
            "[12,    60]\t loss: 1.291\t accuracy: 99.062\n",
            "[12,    70]\t loss: 1.262\t accuracy: 99.062\n",
            "[12,    80]\t loss: 1.305\t accuracy: 98.125\n",
            "[12,    90]\t loss: 1.311\t accuracy: 97.500\n",
            "[12,   100]\t loss: 1.317\t accuracy: 98.125\n",
            "[12,   110]\t loss: 1.339\t accuracy: 96.562\n",
            "[12,   120]\t loss: 1.294\t accuracy: 98.125\n",
            "[12,   130]\t loss: 1.302\t accuracy: 97.812\n",
            "[12,   140]\t loss: 1.341\t accuracy: 97.188\n",
            "[12,   150]\t loss: 1.333\t accuracy: 97.500\n",
            "[12,   160]\t loss: 1.303\t accuracy: 98.438\n",
            "[12,   170]\t loss: 1.311\t accuracy: 98.438\n",
            "[12,   180]\t loss: 1.300\t accuracy: 99.062\n",
            "[12,   190]\t loss: 1.339\t accuracy: 97.812\n",
            "[12,   200]\t loss: 1.321\t accuracy: 97.812\n",
            "[12,   210]\t loss: 1.293\t accuracy: 99.062\n",
            "[12,   220]\t loss: 1.318\t accuracy: 97.500\n",
            "[12,   230]\t loss: 1.333\t accuracy: 98.438\n",
            "[12,   240]\t loss: 1.327\t accuracy: 97.500\n",
            "[12,   250]\t loss: 1.335\t accuracy: 96.562\n",
            "[12,   260]\t loss: 1.299\t accuracy: 99.062\n",
            "[12,   270]\t loss: 1.323\t accuracy: 96.562\n",
            "[12,   280]\t loss: 1.334\t accuracy: 99.062\n",
            "[12,   290]\t loss: 1.291\t accuracy: 99.688\n",
            "[12,   300]\t loss: 1.337\t accuracy: 96.875\n",
            "[12,   310]\t loss: 1.302\t accuracy: 98.750\n",
            "[12,   320]\t loss: 1.324\t accuracy: 97.188\n",
            "[12,   330]\t loss: 1.295\t accuracy: 97.812\n",
            "[12,   340]\t loss: 1.297\t accuracy: 98.750\n",
            "[12,   350]\t loss: 1.330\t accuracy: 97.188\n",
            "[12,   360]\t loss: 1.335\t accuracy: 97.500\n",
            "[12,   370]\t loss: 1.318\t accuracy: 98.438\n",
            "[12,   380]\t loss: 1.288\t accuracy: 99.375\n",
            "[12,   390]\t loss: 1.305\t accuracy: 98.125\n",
            "[12,   400]\t loss: 1.279\t accuracy: 98.125\n",
            "[13,    10]\t loss: 1.273\t accuracy: 99.688\n",
            "[13,    20]\t loss: 1.266\t accuracy: 98.750\n",
            "[13,    30]\t loss: 1.290\t accuracy: 98.125\n",
            "[13,    40]\t loss: 1.271\t accuracy: 99.062\n",
            "[13,    50]\t loss: 1.269\t accuracy: 99.062\n",
            "[13,    60]\t loss: 1.263\t accuracy: 98.750\n",
            "[13,    70]\t loss: 1.271\t accuracy: 99.375\n",
            "[13,    80]\t loss: 1.265\t accuracy: 98.750\n",
            "[13,    90]\t loss: 1.267\t accuracy: 98.125\n",
            "[13,   100]\t loss: 1.280\t accuracy: 98.438\n",
            "[13,   110]\t loss: 1.274\t accuracy: 99.062\n",
            "[13,   120]\t loss: 1.241\t accuracy: 99.688\n",
            "[13,   130]\t loss: 1.250\t accuracy: 99.062\n",
            "[13,   140]\t loss: 1.260\t accuracy: 99.375\n",
            "[13,   150]\t loss: 1.273\t accuracy: 98.438\n",
            "[13,   160]\t loss: 1.291\t accuracy: 98.125\n",
            "[13,   170]\t loss: 1.261\t accuracy: 99.062\n",
            "[13,   180]\t loss: 1.281\t accuracy: 97.812\n",
            "[13,   190]\t loss: 1.259\t accuracy: 100.000\n",
            "[13,   200]\t loss: 1.274\t accuracy: 98.438\n",
            "[13,   210]\t loss: 1.256\t accuracy: 99.688\n",
            "[13,   220]\t loss: 1.270\t accuracy: 99.062\n",
            "[13,   230]\t loss: 1.270\t accuracy: 98.438\n",
            "[13,   240]\t loss: 1.287\t accuracy: 98.438\n",
            "[13,   250]\t loss: 1.252\t accuracy: 98.750\n",
            "[13,   260]\t loss: 1.267\t accuracy: 98.438\n",
            "[13,   270]\t loss: 1.284\t accuracy: 98.750\n",
            "[13,   280]\t loss: 1.243\t accuracy: 99.375\n",
            "[13,   290]\t loss: 1.262\t accuracy: 99.375\n",
            "[13,   300]\t loss: 1.275\t accuracy: 98.125\n",
            "[13,   310]\t loss: 1.286\t accuracy: 99.375\n",
            "[13,   320]\t loss: 1.309\t accuracy: 97.812\n",
            "[13,   330]\t loss: 1.259\t accuracy: 99.375\n",
            "[13,   340]\t loss: 1.289\t accuracy: 97.500\n",
            "[13,   350]\t loss: 1.255\t accuracy: 99.062\n",
            "[13,   360]\t loss: 1.276\t accuracy: 98.438\n",
            "[13,   370]\t loss: 1.301\t accuracy: 98.750\n",
            "[13,   380]\t loss: 1.284\t accuracy: 98.750\n",
            "[13,   390]\t loss: 1.285\t accuracy: 98.125\n",
            "[13,   400]\t loss: 1.277\t accuracy: 98.438\n",
            "[14,    10]\t loss: 1.250\t accuracy: 98.750\n",
            "[14,    20]\t loss: 1.229\t accuracy: 99.062\n",
            "[14,    30]\t loss: 1.220\t accuracy: 99.375\n",
            "[14,    40]\t loss: 1.217\t accuracy: 99.688\n",
            "[14,    50]\t loss: 1.238\t accuracy: 99.375\n",
            "[14,    60]\t loss: 1.236\t accuracy: 99.375\n",
            "[14,    70]\t loss: 1.241\t accuracy: 99.062\n",
            "[14,    80]\t loss: 1.221\t accuracy: 100.000\n",
            "[14,    90]\t loss: 1.253\t accuracy: 98.438\n",
            "[14,   100]\t loss: 1.250\t accuracy: 98.750\n",
            "[14,   110]\t loss: 1.240\t accuracy: 99.062\n",
            "[14,   120]\t loss: 1.228\t accuracy: 99.062\n",
            "[14,   130]\t loss: 1.253\t accuracy: 98.750\n",
            "[14,   140]\t loss: 1.230\t accuracy: 99.375\n",
            "[14,   150]\t loss: 1.236\t accuracy: 99.375\n",
            "[14,   160]\t loss: 1.217\t accuracy: 99.688\n",
            "[14,   170]\t loss: 1.253\t accuracy: 98.750\n",
            "[14,   180]\t loss: 1.238\t accuracy: 99.688\n",
            "[14,   190]\t loss: 1.254\t accuracy: 97.812\n",
            "[14,   200]\t loss: 1.241\t accuracy: 99.062\n",
            "[14,   210]\t loss: 1.236\t accuracy: 99.688\n",
            "[14,   220]\t loss: 1.255\t accuracy: 99.062\n",
            "[14,   230]\t loss: 1.236\t accuracy: 100.000\n",
            "[14,   240]\t loss: 1.252\t accuracy: 99.062\n",
            "[14,   250]\t loss: 1.245\t accuracy: 99.688\n",
            "[14,   260]\t loss: 1.241\t accuracy: 99.375\n",
            "[14,   270]\t loss: 1.259\t accuracy: 98.750\n",
            "[14,   280]\t loss: 1.248\t accuracy: 98.125\n",
            "[14,   290]\t loss: 1.260\t accuracy: 99.062\n",
            "[14,   300]\t loss: 1.242\t accuracy: 99.062\n",
            "[14,   310]\t loss: 1.274\t accuracy: 99.062\n",
            "[14,   320]\t loss: 1.236\t accuracy: 99.062\n",
            "[14,   330]\t loss: 1.249\t accuracy: 99.688\n",
            "[14,   340]\t loss: 1.244\t accuracy: 99.375\n",
            "[14,   350]\t loss: 1.265\t accuracy: 98.125\n",
            "[14,   360]\t loss: 1.255\t accuracy: 99.375\n",
            "[14,   370]\t loss: 1.270\t accuracy: 98.750\n",
            "[14,   380]\t loss: 1.247\t accuracy: 99.062\n",
            "[14,   390]\t loss: 1.255\t accuracy: 99.375\n",
            "[14,   400]\t loss: 1.248\t accuracy: 98.438\n",
            "[15,    10]\t loss: 1.222\t accuracy: 99.688\n",
            "[15,    20]\t loss: 1.241\t accuracy: 99.062\n",
            "[15,    30]\t loss: 1.220\t accuracy: 99.375\n",
            "[15,    40]\t loss: 1.231\t accuracy: 98.750\n",
            "[15,    50]\t loss: 1.192\t accuracy: 100.000\n",
            "[15,    60]\t loss: 1.206\t accuracy: 99.375\n",
            "[15,    70]\t loss: 1.213\t accuracy: 99.688\n",
            "[15,    80]\t loss: 1.216\t accuracy: 99.062\n",
            "[15,    90]\t loss: 1.205\t accuracy: 100.000\n",
            "[15,   100]\t loss: 1.218\t accuracy: 99.688\n",
            "[15,   110]\t loss: 1.221\t accuracy: 98.125\n",
            "[15,   120]\t loss: 1.200\t accuracy: 99.062\n",
            "[15,   130]\t loss: 1.216\t accuracy: 99.375\n",
            "[15,   140]\t loss: 1.207\t accuracy: 100.000\n",
            "[15,   150]\t loss: 1.224\t accuracy: 98.750\n",
            "[15,   160]\t loss: 1.217\t accuracy: 99.688\n",
            "[15,   170]\t loss: 1.217\t accuracy: 99.688\n",
            "[15,   180]\t loss: 1.216\t accuracy: 99.688\n",
            "[15,   190]\t loss: 1.233\t accuracy: 99.375\n",
            "[15,   200]\t loss: 1.212\t accuracy: 99.375\n",
            "[15,   210]\t loss: 1.221\t accuracy: 98.750\n",
            "[15,   220]\t loss: 1.239\t accuracy: 98.750\n",
            "[15,   230]\t loss: 1.241\t accuracy: 100.000\n",
            "[15,   240]\t loss: 1.223\t accuracy: 99.062\n",
            "[15,   250]\t loss: 1.211\t accuracy: 100.000\n",
            "[15,   260]\t loss: 1.221\t accuracy: 99.375\n",
            "[15,   270]\t loss: 1.216\t accuracy: 99.688\n",
            "[15,   280]\t loss: 1.216\t accuracy: 99.375\n",
            "[15,   290]\t loss: 1.211\t accuracy: 99.375\n",
            "[15,   300]\t loss: 1.214\t accuracy: 99.688\n",
            "[15,   310]\t loss: 1.218\t accuracy: 98.438\n",
            "[15,   320]\t loss: 1.224\t accuracy: 98.750\n",
            "[15,   330]\t loss: 1.221\t accuracy: 99.688\n",
            "[15,   340]\t loss: 1.225\t accuracy: 99.688\n",
            "[15,   350]\t loss: 1.214\t accuracy: 98.750\n",
            "[15,   360]\t loss: 1.227\t accuracy: 99.375\n",
            "[15,   370]\t loss: 1.229\t accuracy: 99.375\n",
            "[15,   380]\t loss: 1.244\t accuracy: 99.375\n",
            "[15,   390]\t loss: 1.218\t accuracy: 99.375\n",
            "[15,   400]\t loss: 1.225\t accuracy: 99.062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z6rxSLskJdi"
      },
      "source": [
        "# Testing âœ”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czMswsR5kL5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29fd8c51-bf16-48ce-ca68-53351a6218ea"
      },
      "source": [
        "def evaluate(model, query_loader=None, gallery_loader=None, use_gpu=True):\n",
        "    model.eval()\n",
        "\n",
        "    q_features, q_pids, q_camids = feature_extraction(\n",
        "        model,\n",
        "        query_loader,\n",
        "        use_gpu\n",
        "    )\n",
        "    g_features, g_pids, g_camids = feature_extraction(\n",
        "        model,\n",
        "        gallery_loader,\n",
        "        use_gpu\n",
        "    )\n",
        "\n",
        "    distmat = cosine_distance(q_features, g_features)\n",
        "    distmat = distmat.numpy()\n",
        "\n",
        "    cmc, mAP = eval_rank(\n",
        "        distmat,\n",
        "        q_pids,\n",
        "        g_pids,\n",
        "        q_camids,\n",
        "        g_camids,\n",
        "    )\n",
        "\n",
        "    return cmc, mAP\n",
        "\n",
        "\n",
        "def feature_extraction(model, loader, use_gpu=True):\n",
        "    features_, pids_, camids_ = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader):\n",
        "            imgs, pids, camids = parse_data_for_test(data)\n",
        "            if use_gpu:\n",
        "                imgs = imgs.cuda()\n",
        "            features = model(imgs)\n",
        "            features = features.cpu().clone()\n",
        "            features_.append(features)\n",
        "            pids_.extend(pids)\n",
        "            camids_.extend(camids)\n",
        "    features_ = torch.cat(features_, 0)\n",
        "    pids_ = np.asarray(pids_)\n",
        "    camids_ = np.asarray(camids_)\n",
        "    return features_, pids_, camids_\n",
        "\n",
        "\n",
        "def parse_data_for_test(data):\n",
        "    imgs = data['img']\n",
        "    pids = data['pid']\n",
        "    camids = data['camid']\n",
        "    return imgs, pids, camids\n",
        "\n",
        "\n",
        "def load_model(model, use_gpu):\n",
        "    if use_gpu:\n",
        "       device = torch.device('cuda:0')\n",
        "       model.load_state_dict(torch.load('./pretrained_model.pth'))\n",
        "       model.to(device)\n",
        "    else:\n",
        "       device = torch.device('cpu')\n",
        "       model.load_state_dict(torch.load('./pretrained_model.pth',map_location=device))\n",
        "\n",
        "    return model\n",
        "\n",
        "def print_result(cmc, mAP):\n",
        "      print(\"Dataset statistics:\")\n",
        "      print(\"  ----------------------------------------\")\n",
        "      print(\"  distance  | rank1 | rank5 | mAP\")\n",
        "      print(\"  ----------------------------------------\")\n",
        "      print(\"  cosine    | %.2f  | %.2f  | %.2f \" %(cmc[0], cmc[4], mAP))\n",
        "      print(\"  ----------------------------------------\")\n",
        "\n",
        "def main(use_gpu):\n",
        "    data_preparer = DataPreparer(root='./data')\n",
        "\n",
        "    if torch.cuda.is_available() == False:\n",
        "       use_gpu = False\n",
        "\n",
        "    model = OSNet(num_classes=data_preparer.num_train_pids)\n",
        "    model = load_model(model, use_gpu)\n",
        "\n",
        "    cmc, mAP = evaluate(\n",
        "        model=model,\n",
        "        query_loader=data_preparer.testloader.query,\n",
        "        gallery_loader=data_preparer.testloader.gallery,\n",
        "        use_gpu=use_gpu\n",
        "    )\n",
        "    print_result(cmc, mAP)\n",
        "\n",
        "\n",
        "main(use_gpu = True)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Loading train (source) dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset statistics:\n",
            "  ----------------------------------------\n",
            "  distance  | rank1 | rank5 | mAP\n",
            "  ----------------------------------------\n",
            "  cosine    | 0.74  | 0.89  | 49.87 \n",
            "  ----------------------------------------\n"
          ]
        }
      ]
    }
  ]
}